import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Configuration ---
RESULTS_DIR = "results"
FIGURES_DIR = os.path.join(RESULTS_DIR, "figures")

# Input files generated by the modeling scripts
PROPHET_FILE = os.path.join(RESULTS_DIR, "prophet_forecast_vs_actual_30d.csv")
TF_KERAS_FILE = os.path.join(RESULTS_DIR, "tf_keras_forecast_vs_actual_30d.csv")

# Output file for combined results
COMBINED_FILE = os.path.join(RESULTS_DIR, "combined_forecast_comparison.csv")
METRICS_FILE = os.path.join(RESULTS_DIR, "forecast_metrics.csv")

# --- Main Comparison Script ---
if __name__ == "__main__":
    print("--- Running Comparison for Prophet vs TF/Keras Forecasts ---")
    os.makedirs(FIGURES_DIR, exist_ok=True) # Ensure figures dir exists

    # Load Prophet results
    try:
        df_prophet = pd.read_csv(PROPHET_FILE, sep=';', parse_dates=['Date'], index_col='Date')
        # Keep only Actual and Prophet forecast (drop uncertainty if present)
        if 'Actual' not in df_prophet.columns or 'Prophet_Forecast' not in df_prophet.columns:
             raise ValueError("Prophet file missing required 'Actual' or 'Prophet_Forecast' columns.")
        df_prophet = df_prophet[['Actual', 'Prophet_Forecast']]
        print(f"Loaded Prophet results: {df_prophet.shape}")
    except FileNotFoundError:
        print(f"Error: Prophet results file not found: {PROPHET_FILE}")
        exit()
    except ValueError as e:
        print(f"Error loading Prophet file: {e}")
        exit()

    # Load TF/Keras results
    try:
        df_tf = pd.read_csv(TF_KERAS_FILE, sep=';', parse_dates=['Date'], index_col='Date')
        if 'TF_Keras_Forecast' not in df_tf.columns:
             raise ValueError("TF/Keras file missing required 'TF_Keras_Forecast' column.")
        # Only keep the forecast column, as 'Actual' is already in df_prophet
        df_tf = df_tf[['TF_Keras_Forecast']]
        print(f"Loaded TF/Keras results: {df_tf.shape}")
    except FileNotFoundError:
        print(f"Error: TF/Keras results file not found: {TF_KERAS_FILE}")
        exit()
    except ValueError as e:
        print(f"Error loading TF/Keras file: {e}")
        exit()

    # Merge the dataframes
    # df_prophet already has 'Actual' and 'Prophet_Forecast'
    df_comparison = df_prophet.join(df_tf)

    # Drop rows where any forecast is missing (if files had different date ranges somehow)
    df_comparison.dropna(inplace=True)

    if df_comparison.empty:
        print("Error: No common dates found between forecast files or files are empty.")
        exit()

    print(f"\nCombined comparison data shape: {df_comparison.shape}")
    print("First 5 rows of combined data:")
    print(df_comparison.head())

    # Save combined data
    df_comparison.to_csv(COMBINED_FILE, sep=';')
    print(f"\nCombined forecast data saved to {COMBINED_FILE}")

    # --- Calculate Metrics ---
    print("\nCalculating forecast metrics...")
    metrics = {}
    actual = df_comparison['Actual']

    # Prophet Metrics
    prophet_fc = df_comparison['Prophet_Forecast']
    mae_prophet = mean_absolute_error(actual, prophet_fc)
    rmse_prophet = np.sqrt(mean_squared_error(actual, prophet_fc))
    # MAPE - Handle potential zero values in actual
    mape_prophet = np.mean(np.abs((actual - prophet_fc) / np.where(actual == 0, 1e-6, actual))) * 100
    metrics['Prophet'] = {'MAE': mae_prophet, 'RMSE': rmse_prophet, 'MAPE (%)': mape_prophet}
    print(f"Prophet - MAE: {mae_prophet:.2f}, RMSE: {rmse_prophet:.2f}, MAPE: {mape_prophet:.2f}%")

    # TF/Keras Metrics
    tf_keras_fc = df_comparison['TF_Keras_Forecast']
    mae_tf = mean_absolute_error(actual, tf_keras_fc)
    rmse_tf = np.sqrt(mean_squared_error(actual, tf_keras_fc))
    mape_tf = np.mean(np.abs((actual - tf_keras_fc) / np.where(actual == 0, 1e-6, actual))) * 100
    metrics['TF_Keras'] = {'MAE': mae_tf, 'RMSE': rmse_tf, 'MAPE (%)': mape_tf}
    print(f"TF/Keras - MAE: {mae_tf:.2f}, RMSE: {rmse_tf:.2f}, MAPE: {mape_tf:.2f}%")

    # Save metrics
    df_metrics = pd.DataFrame(metrics).T # Transpose for better readability
    df_metrics.to_csv(METRICS_FILE, sep=';')
    print(f"\nMetrics saved to {METRICS_FILE}")

    # --- Plotting Comparison ---
    print("\nGenerating comparison plot...")
    try:
        plt.figure(figsize=(14, 7))
        plt.plot(df_comparison.index, df_comparison['Actual'], label='Actual (Generated)', color='black', linewidth=2.5, marker='o', markersize=4)
        plt.plot(df_comparison.index, df_comparison['Prophet_Forecast'], label=f'Prophet (MAE: {mae_prophet:.2f})', color='blue', linestyle='--', marker='x', markersize=4)
        plt.plot(df_comparison.index, df_comparison['TF_Keras_Forecast'], label=f'TF/Keras (MAE: {mae_tf:.2f})', color='red', linestyle=':', marker='+', markersize=5)

        plt.title('Model Forecast Comparison vs Actual (April 2025)')
        plt.xlabel('Date')
        plt.ylabel('Value')
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)
        plt.tight_layout() # Adjust layout

        plot_path = os.path.join(FIGURES_DIR, "combined_forecast_comparison.png")
        plt.savefig(plot_path)
        plt.close()
        print(f"Comparison plot saved to {plot_path}")

    except Exception as e:
        print(f"An error occurred during plotting: {e}")

    print("\n--- Comparison script finished ---")